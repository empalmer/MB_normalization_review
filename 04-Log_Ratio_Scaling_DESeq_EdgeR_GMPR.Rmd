# Log-Ratio Based Scaling Methods

## DESeq

### About DESeq

The DESeq2 package includes a normalization method for adjusting for differing library sizes across samples [@anders2010]. This method also can account for differences in library composition. A scaling factor to normalize each sample takes into account both library size and library composition. This method has also been called MED, RLE, or DESeq in the literature.

DESeq2 first takes the natural logarithm of every entry in the count matrix. Due to this, all entries with zero will be set to negative infinity. Next, the row average is calculated (geometric average), so we have a vector of average counts for each taxon. Taking the log first should avoid undue influence by extreme outliers. All taxa with an average of infinity are removed. This step will remove all taxa with zero read count in one or more samples. This can be a problem in microbiome data. Next, we subtract the average log value from the log(counts), this gives a log ratio. This is equivalent to the ratio of the reads in each sample to the average across all samples. Next, we calculate the median of the log-ratios for each sample. These medians are converted to scaling factors for each sample by exponentiation. An extension of this method, denoted 'poscounts', has been suggested, which instead of taking the geometric mean of the logged counts for each taxon, we take the n-th root of the product of the non-zero counts.

This method assumes that the taxon of median absolute abundance is not differentially abundant, which is more likely true for the RNA-Seq it was developed for, but may not be true for microbiome studies, especially when there are more study groups, or we are analyzing higher taxonomic levels.

An additional option can be used to perform a variance stabilizing transformation on the count matrix before normalizing with the above size factors. This method calculates a dispersion-mean relationship and then transforms the data. The result ideally is an abundance matrix that is approximately homoskedastic or constant variance across the range of mean values. The package also includes an option for a 'rlog' transform, which they recommend over the variance stabilizing method in the case when there is a large difference in library sizes.

If differential abundance is of interest to calculate, DESeq uses a negative binomial distribution to model differential abundances. It is possible to provide the size factors calculated by another method to DESeq to perform differential analysis.

### DESeq Implementation


Consider again this example dataset. 


```{r}
sample1 <- c(132, 7, 0, 23, 71)
sample2 <- c(103, 48, 2, 15, 80)
sample3 <- c(11, 3, 1, 2, 5)
taxa <- paste("Taxon", 1:5)

sampling_depth <- c(sum(sample1), sum(sample2), sum(sample3))

tibble(taxa, sample1, sample2, sample3) %>%
    knitr::kable(
        col.names = c("Taxa", "Sample 1", "Sample2", "Sample 3"),
        caption =  "Example dataset - Raw Counts", 
        format = "html"
    ) 
```

The first step in DESeq normalization is to take the natural log of each entry in the count matrix. 

```{r, deseq_step_1}

ds1_df <- tibble(taxa, log(sample1), log(sample2), log(sample3))
ds1_df  %>%
    knitr::kable(
        col.names = c("Taxa", "Sample 1", "Sample2", "Sample 3"),
        caption =  "Step 1: Logged Raw Counts", 
        format = "html"
    ) 
```

Notice the one entry with zero counts is marked as negative infinity. 

Next, the average of the logged values is taken across the samples. This results in an average log value for each taxa. This averaged log value is helpful for normalizing because it is not overwhelmed by outliers. 

```{r deseq_step2}

ds2_df <- tibble(taxa, rowMeans(data.frame(log(sample1), log(sample2), log(sample3))))

ds2_df %>%
    knitr::kable(
        col.names = c("Taxa", "Average Log Counts"),
        caption =  "Step 2: Average Logged Counts"
    ) 
```

The row for the taxa that contained a zero on one of the samples is negative infinity. This taxon is now excluded from the following steps. This step results in removing any taxa that have zero counts from being considered to contribute to calculating the scaling factors. 


<!-- The idea here is to keep housekeeping genes  -->


The next step is to subtract the average log values (step 2) from the log of the raw counts (step 1), only including rows that were not filtered. This step shows which samples have counts in a sample higher or lower than the average. 


```{r, deseq_step3}
s1v <- c(0.91, -.36, .96, .84)
s2v <- c(.66, 1.66, .53, .96)
s3v <- c(-1.57, -1.31, -1.49, -1.81)
s1_diff <-c("4.88 - 3.97 = 0.91",
            "1.95 - 2.31 = -0.36",
            "3.14 - 2.18 = 0.96",
            "4.26 - 3.42 = 0.84")
s2_diff <- c("4.63 - 3.97 = 0.66", 
             "3.97 - 2.31 = 1.66", 
             "2.71 - 2.18 = 0.53",
             "4.38 - 3.42 = 0.96")
s3_diff <- c("2.40 - 3.97 = -1.57",
             "1.10 - 2.31 = -1.31", 
             "0.69 - 2.18 = -1.49", 
             "1.61- 3.42 = -1.81")
taxa_filtered <- taxa[-3]

tibble(taxa_filtered, s1_diff, s2_diff, s3_diff) %>%
    knitr::kable(
        col.names = c("Taxa", "Sample 1", "Sample 2", "Sample 3"),
        caption =  "Step 3: Log Ratio of reads in each sample to average across all samples"
    ) 
```


Next, to calculate the scaling factors for each sample, we take the median of the log ratios calculated in the above step. Like using logs, calculating medians avoids the influence of outlier taxa that put undue influence on the scaling factor.

```{r, deseq_step4}
tibble(c(taxa_filtered, "Median", "Exponentiated Median"),
       c(s1v, median(s1v), exp(median(s1v))),
       c(s2v, median(s2v), exp(median(s2v))),
       c(s3v, median(s3v), exp(median(s3v))))%>%
    knitr::kable(
        col.names = c("Taxa", "Sample 1", "Sample 2", "Sample 3"),
        caption =  "Step 4: Calculating medians per sample"
    ) 
```


Finally, we normalize the data, by exponentiating the median log ratios for each sample, which are the final scaling factors. We then divide all the raw counts in a sample by the sample's scaling factor.

```{r, deseq }
tibble(taxa, sample1/exp(median(s1v)), sample2/exp(median(s2v)), sample3/exp(median(s3v)))  %>%
    knitr::kable(
        col.names = c("Taxa", "Sample 1", "Sample2", "Sample 3"),
        caption =  "Step 5: DESeq Normalized Counts", 
        format = "html"
    ) 
```


Since Taxon 3 had a zero count in sample 1, it was excluded from the calculation of scale factors. The above example dataset may not be characteristic of microbiome datasets. Microbiome datasets are zero-inflated, meaning that there are numerous zero counts in the raw count matrix. Even up to 80-90% of the counts in a microbiome datset can be zero. Because of this, if the zero-inflation in the datseta is not accounted for, very few, or even perhaps none of the taxa will contribute to calculating the scaling factor. One option so that all of the taxa are included in the calculation is to add a pseudocount so none of the counts are zero. Another option is the `poscounts` option, which is encouraged for microbiome data. Instead of taking the average of the logged counts, it takes the $n$th root of the non-zero counts. This replaces step 2 in this example.  




Here we provide two normalization functions implemented in R using DESeq methods. The first calculates the RLE normalization using the `poscounts` option for microbiome data. The second calculates the variance stabilizing transformation. 

```{r, deseq-implementation, warning=FALSE,message=FALSE}
norm_DESeq_RLE_poscounts <- function(ps, group = 1){
  require(DESeq2, quietly = T)
    # keep arbitrary design for normalization 
    # Convert to DESeq object
    ps_dds <- phyloseq_to_deseq2(ps, ~1)
    # Calculate the size factors (scaling)
    ps_dds <- estimateSizeFactors(ps_dds, type = "poscounts")
    # Extract counts
    counts <- DESeq2::counts(ps_dds, normalized = T)
    # Convert back to phyloseq
    otu <- otu_table(counts, taxa_are_rows = T)
    sam <- access(ps, "sam_data")
    sam$scaling_factor <- sizeFactors(ps_dds)
    tax <- access(ps, "tax_table")
    phy <- access(ps, "phy_tree")
    ps_DESeq <- phyloseq(otu,sam,tax,phy)
    return(ps_DESeq)
}



norm_DESeq_vs <- function(ps, group = 1){
  require(DESeq2, quietly = T)
  ps_dds <- phyloseq_to_deseq2(ps, ~ 1)
  ps_dds <- estimateSizeFactors(ps_dds, type = "poscounts")
  # Variance transformation
  ps_dds <- estimateDispersions(ps_dds)
  abund <- getVarianceStabilizedData(ps_dds)
  # donâ€™t allow deseq to return negative counts
  # add the minimum count to all values
  # another option is to replace negative counts with 0
  abund <- abund + abs(min(abund)) 
  otu <- otu_table(abund, taxa_are_rows = T)
  sam <- access(ps, "sam_data")
  tax <- access(ps, "tax_table")
  phy <- access(ps, "phy_tree")
  ps_DESeq <- phyloseq(otu,sam,tax,phy)
  return(ps_DESeq)
}

```

### DESeq on Global Patterns

Perform DESeq RLE normalization as well as DESeq variance stabilized transformation on Global Patterns:

```{r, warning=FALSE,message=FALSE}
gp_deseq_rle <- norm_DESeq_RLE_poscounts(gp_raw)
gp_deseq_vs <- norm_DESeq_vs(gp_raw)
```

Examine principal coordinate plots between raw data and both DESeq normalized data.

```{r deseq-ordination, warning=FALSE,message=FALSE}
# First calculate distance matrices 
gp_rle_dist <- phyloseq::ordinate(gp_deseq_rle, "PCoA", "bray") 
gp_vs_dist <- phyloseq::ordinate(gp_deseq_vs, "PCoA", "bray") 

# Plot ordinations
plot_ordination(gp_raw, gp_raw_dist, color = "SampleType", title = "PCoA on Raw data") + 
plot_ordination(gp_deseq_rle, gp_rle_dist, color = "SampleType", title = "PCoA on RLE") +
plot_ordination(gp_deseq_vs, gp_vs_dist, color = "SampleType", title = "PCoA on VST") + 
  plot_layout(guides = 'collect')
```

See how dissimilarity matrices differ from raw counts and each DESeq transformation.

```{r, warning=FALSE,message=FALSE}
plot_norm_changes(gp_deseq_rle, gp_raw, 
                  x_lab = "Raw", y_lab = "RLE", 
                  title = "Distance metric comparision between RLE normalization and Raw counts ") / 
plot_norm_changes(gp_deseq_vs, gp_raw, 
                  x_lab = "Raw", y_lab = "VST", 
                  title = "Distance metric comparision between VST normalization and Raw counts ") + 
  plot_layout(guides = 'collect')
```


### DESeq on Kostic data 

```{r, warning=FALSE,message=FALSE}
k_deseq_rle <- norm_DESeq_RLE_poscounts(k_raw)
k_deseq_vs <- norm_DESeq_vs(k_raw)

# First calculate distance matrices 
k_rle_dist <- phyloseq::ordinate(k_deseq_rle, "PCoA", "bray") 
k_vs_dist <- phyloseq::ordinate(k_deseq_vs, "PCoA", "bray") 

# Plot ordinations
plot_ordination(k_raw, k_raw_dist, color = "DIAGNOSIS", title = "PCoA on Raw data") + 
plot_ordination(k_deseq_rle, k_rle_dist, color = "DIAGNOSIS", title = "PCoA on RLE") +
plot_ordination(k_deseq_vs, k_vs_dist, color = "DIAGNOSIS", title = "PCoA on VST") + 
  plot_layout(guides = 'collect')

plot_norm_changes(k_deseq_rle, k_raw, 
                  x_lab = "Raw", y_lab = "RLE", 
                  title = "Distance metric comparision between RLE normalization and Raw counts ") / 
plot_norm_changes(k_deseq_vs, k_raw, 
                  x_lab = "Raw", y_lab = "VST", 
                  title = "Distance metric comparision between VST normalization and Raw counts ") + 
  plot_layout(guides = 'collect')
```

